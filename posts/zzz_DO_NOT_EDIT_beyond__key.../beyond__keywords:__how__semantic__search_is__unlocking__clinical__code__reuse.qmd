---
title: "Beyond Keywords: How Semantic Search is Unlocking Clinical Code Reuse"
author:
  - name: Mathieu Cayssol
description: "Finding and reusing clinical programming code is currently slow and scattered. The Code Search Assistant (CSA) fixes this by letting you search code by meaning, not just keywords. It breaks programs into manageable chunks, enriching each with metadata and a short AI summary. Then, when you query the CSA, it returns ranked snippets that match your plain-English question. Each result shows things like the file path, program name, study name, repository, and study description. The result is: quicker reuse of proven code, fewer duplicate implementations, and more consistent programs across studies."
# Note that the date below will be auto-updated when the post is merged.
date: "2025-11-20"
# Please do not use any non-default categories.
# You can find the default categories in the repository README.md
categories: [Metadata, ADaM, TLG, Community, Conferences, Technical]
# Feel free to change the image
image: "pharmaverse.png"

---

<!--------------- typical setup ----------------->

```{r setup, include=FALSE}
long_slug <- "zzz_DO_NOT_EDIT_beyond__key..."
library(link)
link::auto()
```

<!--------------- post begins here ----------------->

## TL;DR

Finding and reusing clinical programming code is currently slow and scattered. The Code Search Assistant (CSA) fixes this by letting you search code by meaning, not just keywords. It breaks programs into manageable chunks, enriching each with metadata and a short AI summary. Then, when you query the CSA, it returns ranked snippets that match your plain-English question. Each result shows things like the file path, program name, study name, repository, and study description. The result is: quicker reuse of proven code, fewer duplicate implementations, and more consistent programs across studies.

## Why this matters for pharmaverse programmers

Clinical reporting follows repeatable patterns—ADaM derivations, TFL layouts, and QC checks—but examples are scattered across templates and repositories. Templates cover most standard outputs; however, for non-standard requests or bespoke TFLs, keyword search often misses intent (e.g., “derive ABLFL in ADLB using a pre-dose baseline rule and analysis-visit windows”) because variable names and structures vary by study. CSA translates that intent into semantic retrieval, surfacing relevant, provenance-linked code snippets even when the wording doesn’t match exactly—so you can review, trust, and reuse.

## What we built?

CSA is a focused agent inside our Clinical Analysis Assistant. A user asks a question; we create an embedding of that query, apply optional metadata filters, search the vector database, and return the most relevant code chunks alongside their origins.

<img width="1015" height="622" alt="Image" src="https://github.com/user-attachments/assets/254c9966-663e-4d21-950c-9dede4939b31" />

Behind the scenes, we index code from our repositories, split it into coherent chunks, and generate short summaries that describe what each piece of code does, its inputs and outputs, and, for TLG programs, details such as titles and footnotes. We embed the summaries, store the vectors, and retain rich metadata such as programming language, file name, repository, and study description. The interface displays both the results and the parameters used so retrieval stays transparent and audit-friendly.


## How it works

### Understand the ask
We transform user's question into a semantic search query + metadata filters.

### Retrieve with context
We perform a semantic search over the vector database + apply substring matching based on the metadata filters. Summaries help match intent (“derive AVALC from PARAMCD”) even if the snippet uses different variable names. The metadata filters help to narrow down the results to the most relevant snippets (e.g: adsl in the program name or phase III in the study description).

### Return with provenance
Results show snippet text, file path, repo, and any available study metadata. You can jump to source for review and reuse.

*Design principle: retrieval should be fast, explainable, and reproducibles. It should be possible to trace back the code to the original source.*


## Example

## Live demo

![Image](https://github.com/user-attachments/assets/df717c39-637a-40ae-a670-f8d9a3f26547)

## What programmers can do today

With CSA, programmers can look up ADaM and TLG scripts by intent, such as *"asking for an ADSL baseline flag with visit windowing"* or *"an AVALC mapping that treats missing values explicitly"*. They can locate TLG programs described in plain English. For instance, a table that splits columns by treatment arm and summarizes AVAL with mean and standard deviation and then adapt a proven layout. They can also compare similar implementations across repositories to converge on a standard approach while maintaining confidence through clear provenance back to source.

## Metrics and usage

Over the observation window, the Code Search Assistant (CSA) handled 791 questions from 45 unique users, averaging 42 ± 14 weekly conversations and 92 ± 43 weekly questions. Satisfaction signals were positive: the broader Clinical Analysis Assistant (CAA) scored 3.39/5 for usefulness (n = 174), while the CSA specifically was rated at ~4/5, indicating strong early traction among active users.

## Limitations & what’s next

Today, CSA focuses on fast, trustworthy discovery. We are working on tighter IDE integration via MCP so you can search directly from your editor. We also want to enable better study awareness so results are automatically filtered to the context of your study and clinical programming code. Finally, we are refining the data pipeline to continuously index changes without any manual effort and adding SDTM programs as well. These steps aim to make retrieval not only smarter but also more seamlessly woven into day-to-day programming.



<!--------------- appendices go here ----------------->

```{r, echo=FALSE}
source("appendix.R")
insert_appendix(
  repo_spec = "pharmaverse/blog",
  name = long_slug,
  # file_name should be the name of your file
  file_name = list.files() %>% stringr::str_subset(".qmd") %>% first()
)
```

