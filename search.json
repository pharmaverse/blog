[
  {
    "objectID": "posts/2023-03-14_hackathon_writeup/index.html#describe-the-participants-using-the-polls",
    "href": "posts/2023-03-14_hackathon_writeup/index.html#describe-the-participants-using-the-polls",
    "title": "Admiral Hackathon 2023 Revisited",
    "section": "describe the participants using the polls",
    "text": "describe the participants using the polls"
  },
  {
    "objectID": "posts/2023-03-14_hackathon_writeup/index.html#how-did-the-workshop-go",
    "href": "posts/2023-03-14_hackathon_writeup/index.html#how-did-the-workshop-go",
    "title": "Admiral Hackathon 2023 Revisited",
    "section": "How did the workshop go?",
    "text": "How did the workshop go?\n(link to hackathon app blogpost)"
  },
  {
    "objectID": "posts/2023-03-14_hackathon_writeup/index.html#conclusion-future-workshops",
    "href": "posts/2023-03-14_hackathon_writeup/index.html#conclusion-future-workshops",
    "title": "Admiral Hackathon 2023 Revisited",
    "section": "conclusion / future workshops",
    "text": "conclusion / future workshops"
  },
  {
    "objectID": "posts/2023-01-09_welcome/index.html",
    "href": "posts/2023-01-09_welcome/index.html",
    "title": "Hello pharmaverse",
    "section": "",
    "text": "The structure of this Blog is based on the GitHub repo of the fantastic blog by Danielle Navarro, please check it out!\nHi there, and welcome to this blog. I am a statistical programmer. I write this blog to have a reference of what I have done previously, and how I did it. Making this public encourages me to write more explicitly, which in turn will make it easier for me to understand the next time I try to do something similar."
  },
  {
    "objectID": "posts/2023-01-09_welcome/index.html#last-updated",
    "href": "posts/2023-01-09_welcome/index.html#last-updated",
    "title": "Hello pharmaverse",
    "section": "Last updated",
    "text": "Last updated\n\n2023-06-07 07:55:27.894011"
  },
  {
    "objectID": "posts/2023-01-09_welcome/index.html#details",
    "href": "posts/2023-01-09_welcome/index.html#details",
    "title": "Hello pharmaverse",
    "section": "Details",
    "text": "Details\n\nsource code, R environment"
  },
  {
    "objectID": "posts/2023-03-14_hackathon_app/index.html",
    "href": "posts/2023-03-14_hackathon_app/index.html",
    "title": "Hackathon Feedback Application",
    "section": "",
    "text": "We recently created a shiny application for the admiral hackathon in February 2023. The admiral hackathon was an event designed to make statistical programmers from the pharmaceutical industry more comfortable with the admiral R package which allows users to efficiently transform data from one data standard (sdtm) to another (adam).\nHackathon participants formed groups of up to five people and were then tasked to create R-scripts that map the sdtm data to adam according to specifics defined in the metadata.\nThe purpose of the shiny app was threefold:\nIn this blog post I want to highlight some of the thoughts that went into this application. Please keep in mind that this work was done under tight time restraints.\nThe hackathon application is still online (although data-upload is switched off) and the GitHub repository is publicly available. I have also uploaded to GitHub a .zip file of the workspace to which hackathon participants had access via posit cloud. For more context you can watch recordings of the hackathon-meetings."
  },
  {
    "objectID": "posts/2023-03-14_hackathon_app/index.html#permanent-data",
    "href": "posts/2023-03-14_hackathon_app/index.html#permanent-data",
    "title": "Hackathon Feedback Application",
    "section": "Permanent Data",
    "text": "Permanent Data\nThe biggest challenge you have to consider for this app is the permanent data storage. Shiny apps run on a server. Although we can write files on this server, whenever the app restarts, the files are lost. Therefore, a persistent data storage solution is required.\n\nGoogle drive\nI decided to leverage Google drive using the googledrive package. This allowed me to save structured data (the team registry and the submission scores) as well as unstructured data (their R-script files).\n\n\n\n\n\n\nAuthentication\n\n\n\nTo access Google drive using the googledrive package we need to authenticate. This can be done interactively using the command googledrive::drive_auth() which takes you to the Google login page. After login you receive an authentication token requested by R.\nFor non-interactive authentication this token must be stored locally. In our case where the shiny app must access the token once deployed, the token must be stored on the project level.\nI have included the authentication procedure I followed in the R folder in google_init.R. You can find more extensive documentation of the non-interactive authentication.\n\n\nThe initial concept was: Each team gets their own folder including the most recent submission for each task, and a .csv file containing team information. To keep track of the submissions and the respective scores we wrote a .csv file in the mock-hackathon folder, so one folder above the team folders.\nSaving the team info as a .csv file worked fine as each team received their own file which â€“ once created â€“ was not touched anymore. As each upload for every team should simply add a row to the submissions.csv file, appending the file would be ideal. This was not possible using the googledrive package. Instead, for each submission, the submissions file was downloaded, appended, and uploaded again. Unfortunately, this lead to a data loss, as the file was continuously overwritten, especially when two teams would submit simultaneously.\n\n\n\n\n\n\nRecover the Lost Data\n\n\n\nWhenever the submissions.csv file was uploaded, the previous version was sent to the Google drive bin. We ended up with over 3000 submissions.csv files containing a lot of redundant information. I had to write the following chunk to first get the unique file IDs of the 3000 submissions.csv files, create an empty submissions data-frame, and then download each file and add its information to the submisisons data-frame. To keep the data-frame as light as possible, after each append I deleted all duplicate submissions.\n\n# get all task_info.csv ID's\n# each row identifies one file in the trash\ntask_info_master &lt;- drive_find(\n  pattern = \"task_info.csv\",\n  trashed = TRUE\n)\n\n\n# set up empty df to store all submissions\norigin &lt;- tibble(\n  score = numeric(),\n  task = character(),\n  team = character(),\n  email = character(),\n  time = character()\n)\n\n# downloads, reads, and returns one csv file given a file id\nget_file &lt;- function(row) {\n  tf &lt;- tempfile()\n  row %&gt;%\n    as_id() %&gt;%\n    drive_download(path = tf)\n  new &lt;- read_csv(tf) %&gt;%\n    select(score, task, team) %&gt;%\n    distinct()\n}\n\n\n# quick and dirty for loop to subsequently download each file, extract information\n#  merge with previous information and squash it (using distinct()).\nfor (i in 1:nrow(task_info_master)) {\n  origin &lt;- rbind(origin, get_file(row = task_info_master[i, ])) %&gt;%\n    distinct()\n\n  # save progress in a separate file after every 100 downloaded and merged sheets\n  if (i %% 100 == 0) {\n    print(i)\n    write_csv(origin, paste(\"prog_data/task_info_prog_\", i, \".csv\", sep = \"\"))\n    # update on progress\n    message(i / nrow(task_info_master) * 100)\n  }\n}\n\nWhen doing such a time-intensive task, make sure to try it first with only a couple of files to see whether any errors are produced. I am not quite sure how long this took but when I returned from my lunch break everything had finished.\n\n\nIf you want to stay in the Google framework, I recommend using the googlesheets4 package for structured data. googlesheets4 allows appending new information to an already existing sheet without the need to download the file first. As both packages follow the same style, going from one to the other is really simple. googlesheets4 requires authentication as well. However, you can reuse the cached token from the googledrive authentication by setting gs4_auth(token = drive_token()).\n\n\nSecurity Concerns\nConnecting a public shiny app to your Google account introduces a security vulnerability in general. Especially so because we implemented the upload of files to Google drive. And even more problematic: We run a user generated script and display some of its output. A malicious party might be able to extract the authentication token of our Google account or could upload malware to the drive.\nTo reduce the risk, I simply created an un-associated Google account to host the drive. There are certainly better options available, but this seemed a reasonable solution achieved with very little effort."
  },
  {
    "objectID": "posts/2023-03-14_hackathon_app/index.html#register-team",
    "href": "posts/2023-03-14_hackathon_app/index.html#register-team",
    "title": "Hackathon Feedback Application",
    "section": "Register Team",
    "text": "Register Team\nWe wanted to allow users to sign up as teams using the shiny app. The app provides a simple interface where users could input a team name and the number of members. This in turn would open two fields for each user to input their name and email address.\nWe do simple checks to make sure at least one valid email address is supplied, and that the group name is acceptable. The group name cannot be empty, already taken, or contain vulgar words.\nThe team registration itself was adding the team information to the Google sheets file event_info into the sheet teams and to create a team folder in which to store the uploaded R files.\nThe checks and registration is implemented in the register_team() function stored in interact_with_google.R.\n\n\n\nScreenshot of the register team interface\n\n\nThe challange here was to adapt the number of input fields depending on the number of team members. This means that the team name and email interface must be rendered: First, we check how many team members are part of the group, this is stored in the input$n_members input variable. Then we create a tagList with as many elements as team members. Each element contains two columns, one for the email, one for the member name. This tagList is then returned and displayed to the user.\n\n  # render email input UI of the register tab\n  output$name_email &lt;- shiny::renderUI({\n    # create field names\n    N &lt;- input$n_members\n    NAME &lt;- sapply(1:N, function(i) {\n      paste0(\"name\", i)\n    })\n    EMAIL &lt;- sapply(1:N, function(i) {\n      paste0(\"email\", i)\n    })\n    \n    output &lt;- tagList()\n\n    \n    firstsecondthird &lt;- c(\"First\", \"Second\", \"Third\", \"Fourth\", \"Fifth\")\n    for (i in 1:N) {\n      output[[i]] &lt;- tagList()\n      output[[i]] &lt;- fluidRow(\n        shiny::h4(paste(firstsecondthird[i], \" Member\")),\n        column(6,\n          textInput(NAME[i], \"Name\"),\n          value = \" \" # displayed default value\n        ),\n        column(6,\n          textInput(EMAIL[i], \"Email\"),\n          value = \" \"\n        )\n      )\n    }\n    output\n  })\n\nThe team information is then uploaded to Google drive. Because some teams have more members than others, we have to create the respective data-frame with the number of team members in mind.\nThe following chunk creates the registration data. Noteworthy here the creation of the NAME and EMAIL variables which depend on the number of members in this team. Further, the user input of these fields is extracted via input[[paste0(NAME[i])]] within a for-loop.\nWe also make the data-creation dependent on the press of the Register Group button and cache some variables.\n\n  ## registration \n  registrationData &lt;-\n    reactive({\n      N &lt;- input$n_members\n      NAME &lt;- sapply(1:N, function(i) {\n        paste0(\"name\", i)\n      })\n      EMAIL &lt;- sapply(1:N, function(i) {\n        paste0(\"email\", i)\n      })\n      names &lt;- character(0)\n      emails &lt;- character(0)\n\n      for (i in 1:N) {\n        names[i] &lt;- input[[paste0(NAME[i])]]\n        emails[i] &lt;- input[[paste0(EMAIL[i])]]\n      }\n      # create df\n      dplyr::tibble(\n        team_name = input$team_name,\n        n_members = N,\n        member_name = names,\n        member_email = emails\n      )\n    }) %&gt;%\n    bindCache(input$team_name, input$n_members, input$name1, input$email1) %&gt;%\n    bindEvent(input$register) # wait for button press"
  },
  {
    "objectID": "posts/2023-03-14_hackathon_app/index.html#upload-source-script",
    "href": "posts/2023-03-14_hackathon_app/index.html#upload-source-script",
    "title": "Hackathon Feedback Application",
    "section": "Upload & Source Script",
    "text": "Upload & Source Script\nTo upload a script, participants had to select their team first. The input options were based on the existing folders on the Google-drive in the mock_hackathon folder. To upload a particular script participants had to also select the task to be solved. The uploaded script is then uploaded to the team folder following a standardised script naming convention.\nThere are different aspects to be aware of when sourcing scripts on a shiny server. For example, you have to anticipate the packages users will include in their uploaded scripts, as their scripts will load but not install packages. Further, you should keep the global environment of your shiny app separate from the environment in which the script is sourced. This is possible by supplying an environment to the source() function, e.g: source(path_to_script, local = new.env())\nAnother thing we had to consider was to replicate the exact folder-structure on the shiny server that participants were working with when creating the scripts, as they were required to source some scripts and to save their file into a specific folder. This was relatively straight forward as we provided participants with a folder structure in the posit cloud instance they were using. They had access to the sdtm folder in which the data was stored, and the adam folder into which they saved their solutions. The structure also included a folder with metadata which was also available on the shiny server. For some tasks, participants required some adam-datasets stored in the adam folder, essentially the output from previous tasks.\nThis was achieved by first creating a list mapping tasks to the required adam datasets:\n\ndepends_list &lt;- list(\n  \"ADADAS\" = c(\"ADSL\"),\n  \"ADAE\" = c(\"ADSL\"),\n  \"ADLBC\" = c(\"ADSL\"),\n  \"ADLBH\" = c(\"ADSL\"),\n  \"ADLBHY\" = c(\"ADSL\"),\n  \"ADSL\" = NULL,\n  \"ADTTE\" = c(\"ADSL\", \"ADAE\"),\n  \"ADVS\" = c(\"ADSL\")\n)\n\nThis list is sourced from the R/parameters.R file when initiating the application. We then call the get_depends() function sourced from R/get_depends.R which copies the required files from the key folder (where our solutions to the tasks were stored) to the adam folder. After sourcing the uploaded script the content in the adam folder is deleted."
  },
  {
    "objectID": "posts/2023-03-14_hackathon_app/index.html#compare-to-solution-file",
    "href": "posts/2023-03-14_hackathon_app/index.html#compare-to-solution-file",
    "title": "Hackathon Feedback Application",
    "section": "Compare to Solution File",
    "text": "Compare to Solution File\nWe want to compare the file created by participants with our solution (key) file stored in the key folder. The diffdf::diffdf() function allows for easy comparison of two data-frames and directly provides extensive feedback for the user:\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ndf1 &lt;- tibble(\n  numbers = 1:10,\n  letters = LETTERS[1:10]\n)\ndf2 &lt;- tibble(\n  numbers = 1:10,\n  letters = letters[1:10]\n)\n\ndiffdf::diffdf(df1, df2)\n\nWarning in diffdf::diffdf(df1, df2): \nNot all Values Compared Equal\n\n\nDifferences found between the objects!\n\nA summary is given below.\n\nNot all Values Compared Equal\nAll rows are shown in table below\n\n  =============================\n   Variable  No of Differences \n  -----------------------------\n   letters          10         \n  -----------------------------\n\n\nAll rows are shown in table below\n\n  ========================================\n   VARIABLE  ..ROWNUMBER..  BASE  COMPARE \n  ----------------------------------------\n   letters         1         A       a    \n   letters         2         B       b    \n   letters         3         C       c    \n   letters         4         D       d    \n   letters         5         E       e    \n   letters         6         F       f    \n   letters         7         G       g    \n   letters         8         H       h    \n   letters         9         I       i    \n   letters        10         J       j    \n  ----------------------------------------"
  },
  {
    "objectID": "posts/2023-03-14_hackathon_app/index.html#score",
    "href": "posts/2023-03-14_hackathon_app/index.html#score",
    "title": "Hackathon Feedback Application",
    "section": "Score",
    "text": "Score\nTo compare submissions between participants we implemented a simple scoring function (score_f()) based on the table comparison by diffdf(). The function can be found in the compare_dfs.R file:\n\nscore_f &lt;- function(df_user, df_key, keys) {\n  score &lt;- 10\n  diff &lt;- diffdf::diffdf(df_user, df_key, keys = keys)\n  if (!diffdf::diffdf_has_issues(diff)) {\n    return(score)\n  }\n\n  # check if there are any differences if the comparison is not strict:\n  if (!diffdf::diffdf_has_issues(diffdf::diffdf(df_user,\n    df_key,\n    keys = keys,\n    strict_numeric = FALSE,\n    strict_factor = FALSE\n  ))) {\n    # if differences are not strict, return score - 1\n    return(score - 1)\n    \n  }\n  \n  return(round(min(max(score - length(diff) / 3, 1), 9), 2))\n}\n\nEvery comparison starts with a score of 10. We then subtract the length of the comparison object divided by a factor of 3. The length of the comparison object is a simplified way to represent the difference between the two data-frames by one value. Finally, the score is bounded by 1 using max(score, 1).\nThe score is not a perfect capture of the quality of the script uploaded but: 1. helped participants get an idea of how close their data-frame is to the solution file 2. allowed us to raffle prizes based on the merit of submitted r-scripts"
  },
  {
    "objectID": "posts/2023-03-14_hackathon_app/index.html#reactiveness",
    "href": "posts/2023-03-14_hackathon_app/index.html#reactiveness",
    "title": "Hackathon Feedback Application",
    "section": "Reactiveness",
    "text": "Reactiveness\nSome of the app functions can take quite some time to execute, e.g.Â running the uploaded script. Other tasks, e.g.Â registering a team, do not intrinsically generate user facing outputs. This would make the app using really frustrating, as users would not know whether the app is correctly working or whether it froze.\nWe implemented two small features that made the app more responsive. One is simple loading icons that integrate into the user interface and show that output is being computed â€“ that something is working. The other is a pop up window which communicates whether team registration was successful, and if not, why not. We further aimed to forward errors generated by the uploaded scripts to the user interface, but errors generated by the application itself should be concealed."
  },
  {
    "objectID": "posts/2023-03-14_hackathon_app/index.html#conclusion",
    "href": "posts/2023-03-14_hackathon_app/index.html#conclusion",
    "title": "Hackathon Feedback Application",
    "section": "Conclusion",
    "text": "Conclusion\nAlthough the application was continuously improved during the hackathon it proved to be a useful resource for participants from day one as it allowed groups to set their own pace. It further allowed admiral developers to gain insights on package usage of a relatively large sample of potential end users. From our perspective, the application provided a great added value to the hackathon and eased the workload of guiding the participants through all the tasks."
  },
  {
    "objectID": "posts/2023-01-09_CICD_spelling/index.html",
    "href": "posts/2023-01-09_CICD_spelling/index.html",
    "title": "Using CICD to check spelling in quarto documents",
    "section": "",
    "text": "As a data scientist or R programmer, you may be familiar with the benefits of version control systems like GitHub for tracking changes to your code base and collaborating with others. But did you know that you can also use GitHub to automate the testing, building, and deployment of your R projects? This process, known as continuous integration and deployment (CICD), can save you time and effort by ensuring that your code is always in a deploy-able state and by automatically delivering new updates to your users. In this blog post, we will show you how to set up CICD for your quarto documents on GitHub, including configuring a build pipeline and integrating a spelling checker. By the end of this tutorial, you will have a workflow in place that helps you catch spelling mistakes before they make it into your final documents."
  },
  {
    "objectID": "posts/2023-01-09_CICD_spelling/index.html#cicd",
    "href": "posts/2023-01-09_CICD_spelling/index.html#cicd",
    "title": "Using CICD to check spelling in quarto documents",
    "section": "CICD",
    "text": "CICD\nCICD is often used in GitHub projects for package development where it helps to maintain a certain code-quality and style consistency across different contributors and developers. For R projects other than packages CICD is used much less frequently. I belief that setting up CICD pipelines for less complex projects with only very few contributors is still useful to ensure consistent style, spelling, and more.\nAs I am occasionally involved in creating teaching materials in R using quarto, I wanted to implement some CICD checks for quarto documents. As most out-of-the-box CICD pipelines are designed for package development, existing pipelines needed some adjustment to work with other R projects."
  },
  {
    "objectID": "posts/2023-01-09_CICD_spelling/index.html#aim",
    "href": "posts/2023-01-09_CICD_spelling/index.html#aim",
    "title": "Using CICD to check spelling in quarto documents",
    "section": "Aim",
    "text": "Aim\nWhen creating teaching materials in R I rely on GitHub for version control. Generally, I have a main-branch which deploys to a GitHub-page displaying the rendered content. The development of materials happens on the devel branch with a pending merge request to the main branch. Whenever a chapter or a section is ready to be published, I merge the branches. I wanted to create a pipeline that runs a spell-check on all my quarto files on the merge request with main, i.e.: Whenever I push to devel I want GitHub to run the CICD pipeline to check my spelling. As an example, I will show how to implement spelling CICD on this blog-project."
  },
  {
    "objectID": "posts/2023-01-09_CICD_spelling/index.html#spell-check",
    "href": "posts/2023-01-09_CICD_spelling/index.html#spell-check",
    "title": "Using CICD to check spelling in quarto documents",
    "section": "Spell-check",
    "text": "Spell-check\nBecause R is all I know, I would like to use an R-package to do the spell-checking. The spelling package is well suited for the task, as it allows to spell-check all files at once. Before we try to implement the CICD pipeline, the spell-checker has to work locally, so we first install and load the package:\n\ninstall.packages(spelling)\n\n\nlibrary(tidyverse)\n\nâ”€â”€ Attaching core tidyverse packages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse 1.3.2.9000 â”€â”€\nâœ” dplyr     1.1.0.9000     âœ” readr     2.1.3     \nâœ” forcats   0.5.2          âœ” stringr   1.5.0     \nâœ” ggplot2   3.4.0          âœ” tibble    3.1.8     \nâœ” lubridate 1.9.0          âœ” tidyr     1.2.1     \nâœ” purrr     1.0.1          \nâ”€â”€ Conflicts â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ tidyverse_conflicts() â”€â”€\nâœ– dplyr::filter() masks stats::filter()\nâœ– dplyr::lag()    masks stats::lag()\nâ„¹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\nlibrary(spelling)\n\nIf you are working on a package, you can directly use the function spell_check_package() and the spelling package will do so. If you are working on any other R project you have to use the spell_check_files() function and you have to include a path to the files you want to check. Letâ€™s check just this file:\n\n# 2023-01-09_CICD-spelling/\nspelling::spell_check_files(path = \"index.qmd\") %&gt;%\n  head()\n\n  WORD      FOUND IN\naff       index.qmd:348,349,350\ncallout   index.qmd:114\nCICD      index.qmd:2,6,8,16,27,28,31,33,34,35,37,38,46,47,53,70,122,139,167,170,172,173,174,176,278,322,411,412,415\ncran      index.qmd:103\nde        index.qmd:349,350,357,367,391,400,401,414\ndesc      index.qmd:261,305,399\n\n\nIt looks like there are a few words that spelling did not recognize. We should carefully look through the full list and decide whether any mistakes were made. We would not want the GitHub action to prohibit a merge request for any of these words, as there are no typos present (I hope). Therefore, we want to add these words to a file that include words to be ignored by the spelling package.\nIf you are working on a package, this is easy, you can use the spelling::update_wordlist() function. We simply save the list of words as a .txt file. For now, we save it in the working directory.\n\nwrite(spelling::spell_check_files(path = \"index.qmd\")[[1]], \"WORDLIST.txt\")\n\nThe file looks like this:\n\nread_lines(\"WORDLIST.txt\")\n\n [1] \"aff\"            \"callout\"        \"CICD\"           \"cran\"          \n [5] \"de\"             \"desc\"           \"dic\"            \"djnavarro\"     \n [9] \"doch\"           \"eval\"           \"frami\"          \"FRAMI\"         \n[13] \"german\"         \"github\"         \"hÃ¶rt\"           \"https\"         \n[17] \"hunspell\"       \"Ã¬nst\"           \"jeder\"          \"JetBrains\"     \n[21] \"JW\"             \"lang\"           \"lockfile\"       \"md\"            \n[25] \"nur\"            \"png\"            \"pre\"            \"qmd\"           \n[29] \"qmd's\"          \"readme\"         \"readr\"          \"renv\"          \n[33] \"repo\"           \"Rproj\"          \"Rscript\"        \"StefanThoma\"   \n[37] \"subfolders\"     \"testthat\"       \"Thoma\"          \"tidyverse\"     \n[41] \"ubuntu\"         \"verowokjnsthet\" \"versteht\"       \"versthet\"      \n[45] \"von\"            \"wordlist\"       \"WORDLIST\"       \"xportr\"        \n[49] \"yaml\"           \"yml\"            \"zitat\"          \"Zitat\"         \n\n\nNow we can tell spelling to ignore the words in this file from typo-detection:\n\nspelling::spell_check_files(\n  path = \"index.qmd\",\n  ignore = read_lines(\"WORDLIST.txt\")\n)\n\nNo spelling errors found.\n\n\nYou can find a more comprehensive guide to the spelling package in the package manual.\n\n# we can get all qmd's in a project by\nlist.files(\n  path = \"../..\", # first setting the path to the project\n  recursive = TRUE, # include subfolders\n  pattern = \".*.qmd$\"\n) # include only files ending in .qmd\n\n[1] \"index.qmd\"                                   \n[2] \"posts/2023-01-09_CICD_spelling/index.qmd\"    \n[3] \"posts/2023-01-09_welcome/index.qmd\"          \n[4] \"posts/2023-03-14_hackathon_app/index.qmd\"    \n[5] \"posts/2023-03-14_hackathon_writeup/index.qmd\"\n\n\n\n\n\n\n\n\npath\n\n\n\nThe structure of this project is such that each blog-post .qmd file is two folders down from the .Rproj file. The working directory of the .qmd blog-post file is where the file is located. If I want to list files or save files in a higher order folder I need to adjust my path to first go two folders up. I do this by adding \"../..\" to my file paths.\nThe working directory of the CICD pipeline is by default on project level, therefore, the \"../..\" is not required.\n\n\n\nwordlist &lt;- list.files(\n  path = \"../..\",\n  recursive = TRUE,\n  full.names = TRUE,\n  pattern = \".*.qmd$\"\n) %&gt;%\n  spelling::spell_check_files()\n\nNow you should take a good look at the output and fix any typos spotted.\nWhat remains is a list of words to be ignored. They can now be saved into a project level WORDLIST_EXAMPLE.txt file to be accessed later by our CICD workflow.\n\nwrite(x = wordlist[[1]], file = \"../../inst/WORDLIST_EXAMPLE.txt\")\n\nCheck again with WORDLIST_EXAMPLE.txt:\n\nlist.files(\n  path = \"../..\",\n  recursive = TRUE,\n  full.names = TRUE,\n  pattern = \".*.qmd$\"\n) %&gt;%\n  spelling::spell_check_files(ignore = read_lines(\"../../inst/WORDLIST_EXAMPLE.txt\"))\n\nNo spelling errors found.\n\n\nLooks like it worked â€” great!\n\nAppend WORDLIST\nIt makes sense to check the spelling locally before you push to your develop branch. For this purpose I create an r-script where I can run the spell-check for the project and where I can also append the WORDLIST.txt file if needed.\n\n#-------------------------- spell-check ----------------------------------------\n\n# create empty wordlist:\n# write(\"\", file =   \"../../inst/WORDLIST_EXAMPLE.txt\")\n# check spelling:\nspelling::spell_check_files(list.files(pattern = \".*.qmd$\", recursive = TRUE),\n  ignore = readr::read_lines(\"inst/WORDLIST_EXAMPLE.txt\")\n)\n\n# now check those words and whether or not they are really mistakes.\n# once you fixed all mistaked you can:\nwords &lt;- spelling::spell_check_files(list.files(pattern = \".*.qmd$\", recursive = TRUE),\n  ignore = readr::read_lines(\"inst/WORDLIST_EXAMPLE.txt\")\n)\n# now you can add words to the wordlist\n#-- uncomment the following line\n# write(words[[1]], file =   \"inst/WORDLIST_EXAMPLE.txt\", append = TRUE)\n\nspelling::spell_check_files(list.files(pattern = \".*.qmd$\", recursive = TRUE),\n  ignore = readr::read_lines(\"inst/WORDLIST_EXAMPLE.txt\")\n)"
  },
  {
    "objectID": "posts/2023-01-09_CICD_spelling/index.html#setup-cicd-workflow",
    "href": "posts/2023-01-09_CICD_spelling/index.html#setup-cicd-workflow",
    "title": "Using CICD to check spelling in quarto documents",
    "section": "Setup CICD Workflow",
    "text": "Setup CICD Workflow\nNow this needs to be implemented in the CICD pipeline. To implement GitHub CICD I create a folder .github in the project directory, and the folder workflows within the .github folder. This is where CICD pipelines are stored.\nCICD pipelines are written in yaml format, it should look like this:\n#| eval: false\nname: Spellcheck\non:\n  pull_request: {branches: ['main']}\njobs:\n  Spelling:\n    runs-on: ubuntu-latest\n    container: {image: \"rocker/tidyverse:4.2.1\"}\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v3\n\n      - name: Install spelling\n        run: if (!require(\"spelling\")) install.packages(\"spelling\")\n        shell: Rscript {0}\n\n      - name: Run Spelling Check test\n        run: spelling::spell_check_files(list.files(pattern = \".*.qmd$\", recursive = TRUE), ignore = readr::read_lines(\"inst/WORDLIST_EXAMPLE.txt\"))\n        shell: Rscript {0}\nThe first few lines define the name of the workflow (Spellcheck) and when it should be executed.\n\nIn this case, the action runs on pull requests to the main branch.\n#| eval: false\nname: Spellcheck\non:\n  pull_request: {branches: ['main']}\nThen, we define the job to run:\njobs:\n  Spelling:\n    runs-on: ubuntu-latest\n    container: {image: \"rocker/tidyverse:4.2.1\"}\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v3\n\n      - name: Install spelling\n        run: if (!require(\"spelling\")) install.packages(\"spelling\")\n        shell: Rscript {0}\n\n      - name: Run Spelling Check test\n        run: spelling::spell_check_files(list.files(pattern = \".*.qmd$\", recursive = TRUE), ignore = readr::read_lines(\"inst/WORDLIST_EXAMPLE.txt\"))\n        shell: Rscript {0}\n        \nWe run just one job called Spelling.\nIt is run on a docker image deployed by GitHub. We use a particular docker image that comes with R and tidyverse pre-installed, this eases the use of R in this image.\nThe actual workflow is defined in the steps (which can be named) â€” here we only have three steps.\n\nactions/checkout@v3 loads the GitHub repository so the subsequent steps can reference the repo.\nNext, the Install spelling step installs the R package spelling. This is written in R code, so we need to specify that we run the command in R. We do this with the instruction shell: Rscript {0}.\nAt last, we run the spell check in R. By default, the code is executed in the project level directory, so we do not need to adjust the path in the list.files() function to go up the project directory. The same goes for the Ã¬nst/WORDLIST_EXAMPLE.txt file.\n\nNow while this works, it will not throw an error if typos are spotted. We can remedy this by writing code that throws an error if there is a typo. The testthat package is designed to test R code for packages. We use its test_that() function together with the expect_equal() function where we can specify the test we want to conduct. Our test is simple: As the object argument we run the spell-check from above. The output we expect is a spell-check that did not result in any error. We have to supply such an object representing a flawless spell-check in the expected argument. To always get such an object we simply spell-check the WORDLIST_EXAMPLE.txt file using itself as the list of words to ignore:\n\ntestthat::test_that(\n  desc = \"No Typo\",\n  code = testthat::expect_equal(\n    object = spelling::spell_check_files(\n      path = list.files(\n        path = \"../..\", pattern = \".*.qmd$\",\n        recursive = TRUE, full.names = TRUE\n      ),\n      ignore = readr::read_lines(\"../../inst/WORDLIST_EXAMPLE.txt\")\n    ),\n    expected = spelling::spell_check_files(\n      path = \"../../inst/WORDLIST_EXAMPLE.txt\",\n      ignore = readr::read_lines(\"../../inst/WORDLIST_EXAMPLE.txt\")\n    )\n  )\n)\n\nTest passed ðŸŒˆ\n\n\nWe can now implement this test into our CICD workflow:\n\nname: Spellcheck\non:\n  pull_request: {branches: ['main']}\njobs:\n  Spelling:\n    runs-on: ubuntu-latest\n    container: {image: \"rocker/tidyverse:4.2.1\"}\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v3\n\n      - name: Install spelling\n        run: if (!require(\"spelling\")) install.packages(\"spelling\")\n        shell: Rscript {0}\n\n      - name: Run Spelling Check test\n        run: spelling::spell_check_files(list.files(pattern = \".*.qmd$\", recursive = TRUE), ignore = readr::read_lines(\"inst/WORDLIST_EXAMPLE.txt\"))\n        shell: Rscript {0}\n\n      - name: Install testthat\n        run: if (!require(\"testthat\")) install.packages(\"testthat\")\n        shell: Rscript {0}\n\n      - name: test typos\n        run: testthat::test_that(desc = \"No Typo\", code = {\n        no_problem &lt;- spelling::spell_check_files(path = \"inst/WORDLIST_EXAMPLE.txt\", ignore = readr::read_lines(\"inst/WORDLIST_EXAMPLE.txt\"))\n        spellcheck &lt;- spelling::spell_check_files(list.files(pattern = \".*.qmd$\", recursive = TRUE), ignore = readr::read_lines(\"inst/WORDLIST_EXAMPLE.txt\"))\n        testthat::expect_equal(object = spellcheck, expected = no_problem)\n        })\n        shell: Rscript {0}"
  },
  {
    "objectID": "posts/2023-01-09_CICD_spelling/index.html#change-language",
    "href": "posts/2023-01-09_CICD_spelling/index.html#change-language",
    "title": "Using CICD to check spelling in quarto documents",
    "section": "Change language",
    "text": "Change language\nThis works fine for English, but what if we write in German? The spelling package depends on the hunspell package. This package comes with the English dictionary pre-installed. Further, it looks at the user library for any other dictionaries requested in the spelling function call.\nWe can add dictionaries to the user library in the OS we are using to locally check the spelling in our projects. As soon as we want to spell-check on GitHub (with CICD) it gets a bit more tricky because we need to reference a library file within the CICD workflow.\nLetâ€™s write a file that contains a German quote (by JW von Goethe).\n\n# zitat &lt;- file(\"Zitat.txt\", encoding = \"UTF-8\")\n# write(x = \"Es hÃ¶rt doch jeder nur, was er verowokjnsthet.\", file = \"Zitat.txt\")\nwrite_lines(\"Es hÃ¶rt doch jeder nur, was er versthet.\", file = \"Zitat.txt\")\n\nThe spelling package does not recognize the language in a file:\n\nspelling::spell_check_files(\"Zitat.txt\")\n\n  WORD       FOUND IN\ndoch       Zitat.txt:1\nhÃ¶rt      Zitat.txt:1\njeder      Zitat.txt:1\nnur        Zitat.txt:1\nversthet   Zitat.txt:1\n\n\nWe can list the dictionaries that are currently available to the hunspell package.\n\nhunspell::list_dictionaries()\n\n[1] \"en_AU\" \"en_CA\" \"en_GB\" \"en_US\"\n\n\nApparently, only English dictionaries are available at the moment. You can download UTF-8 encoded dictionaries from the LibreOffice GitHub repo fork. For me, the easiest way was to download the entire repo as a .zip folder and then move the dictionary files manually into the repo in which you want to spell-check using that dictionary.\nhunspell requires two dictionary files for a language: the .dic and the .aff file. In this example we take the German dictionary files de_DE_frami.aff and de_DE_frami.dic and save them in the inst folder where our WORDLIST_EXAMPLE.txt file is as well. I am not sure why, but sometimes hunspell will look for the file de_CH_FRAMI.dic when we specify lang = \"inst/de_CH_frami\" so make sure to rename the .dic and .aff files as de_DE_FRAMI.aff and de_DE_FRAMI.dic, just to be sure.\n\nlist.files(\"../../inst\")\n\n[1] \"de_CH_FRAMI.aff\"      \"de_CH_FRAMI.dic\"      \"de_DE_FRAMI.aff\"     \n[4] \"de_DE_FRAMI.dic\"      \"WORDLIST_EXAMPLE.txt\" \"WORDLIST.txt\"        \n\n\n\nspelling::spell_check_files(\"Zitat.txt\", lang = \"../../inst/de_CH_FRAMI\")\n\n  WORD        FOUND IN\nversthet.   Zitat.txt:1\n\n\nNow we just have to fix the error and check again.\n\nwrite_lines(\"Es hÃ¶rt doch jeder nur, was er versteht.\", file = \"Zitat.txt\")\n\n\nspelling::spell_check_files(\"Zitat.txt\", lang = \"../../inst/de_CH_FRAMI\")\n\nNo spelling errors found.\n\n\nThe .yml file for the german spell-check would like this:\n\nname: Spellcheck\non:\n  pull_request: {branches: ['main']}\njobs:\n  Spelling:\n    runs-on: ubuntu-latest\n    container: {image: \"rocker/tidyverse:4.2.1\"}\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v3\n\n      - name: Install spelling\n        run: if (!require(\"spelling\")) install.packages(\"spelling\")\n        shell: Rscript {0}\n\n      - name: Run Spelling Check test\n        run: spelling::spell_check_files(list.files(pattern = \".*.qmd$\", recursive = TRUE), ignore = readr::read_lines(\"inst/WORDLIST.txt\"), lang = \"inst/de_CH_frami\")\n        shell: Rscript {0}\n\n      - name: Install testthat\n        run: if (!require(\"testthat\")) install.packages(\"testthat\")\n        shell: Rscript {0}\n\n      - name: test typos\n        run: testthat::test_that(desc = \"No Typo\", code = {\n        no_problem &lt;- spelling::spell_check_files(path = \"inst/WORDLIST_EXAMPLE.txt\", ignore = readr::read_lines(\"inst/WORDLIST_EXAMPLE.txt\"), lang = \"inst/de_CH_FRAMI\")\n        spellcheck &lt;- spelling::spell_check_files(list.files(pattern = \".*.qmd$\", recursive = TRUE), ignore = readr::read_lines(\"inst/WORDLIST_EXAMPLE.txt\"), lang = \"inst/de_CH_FRAMI\")\n        testthat::expect_equal(object = spellcheck, expected = no_problem)\n        })\n        shell: Rscript {0}"
  },
  {
    "objectID": "posts/2023-01-09_CICD_spelling/index.html#conclusion",
    "href": "posts/2023-01-09_CICD_spelling/index.html#conclusion",
    "title": "Using CICD to check spelling in quarto documents",
    "section": "Conclusion",
    "text": "Conclusion\nYou should now be able to run a spell-check on your quarto files. Further, you know how to implement a GitHub CICD pipeline for spell-checks in any language with available dictionary files. This also allows you to implement other R-code based CICD pipelines.\nFor your (and my) convenience, I have created book-templates for both English and German quarto books. They include CICD pipelines for both spelling and style check, and also implement a CICD publishing workflow. Please read the respective readme.md file for more information."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Clinical Reporting in R",
    "section": "",
    "text": "â€“&gt;  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHello pharmaverse\n\n\n\nBlogging\n\n\n\nWhat am I doing here?\n\n\n\nBen Straub\n\n\nApr 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdmiral Hackathon 2023 Revisited\n\n\n\ncommunity\n\n\nWIP\n\n\n\nLetâ€™s have a look at the Admiral Hackathon 2023 together.\n\n\n\nStefan Thoma\n\n\nApr 24, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHackathon Feedback Application\n\n\n\nR\n\n\nshiny\n\n\nteaching\n\n\nWIP\n\n\n\nGoing through the process of creating a shiny app for the admiral hackathon. The shiny app allows users to check their solutions autonomously, gives feedback, and ratesâ€¦\n\n\n\nStefan Thoma\n\n\nMar 14, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUsing CICD to check spelling in quarto documents\n\n\n\nCICD\n\n\nR\n\n\nGitHub\n\n\nQuarto\n\n\n\nThis post explains how to use GitHub to automatically check the spelling of your quarto document through the process of continuous integration and deployment (CICD).\n\n\n\nStefan Thoma\n\n\nMar 7, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  }
]